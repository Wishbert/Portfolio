{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16_Malaria.ipynb",
      "provenance": [],
      "mount_file_id": "1rIzUoekOsS5UCcCEyS8o7O24Fzlml909",
      "authorship_tag": "ABX9TyPqOM/NdMB09B+MeMOxrdoq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wishbert/Portfolio/blob/main/VGG16_Malaria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubfZqG3DL6tK"
      },
      "source": [
        "# The code below is meant to test the accuracy of the VGG16 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e9t0H8LMJtS"
      },
      "source": [
        "Below is a classification of Malaria Cells. The dataset used contains images of the infected cells and unifected cells The images are of different sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMx4x1B7HcBU",
        "outputId": "615e805d-fa47-4f12-eba8-425a7e5b0d04"
      },
      "source": [
        "!curl -O ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/cell_images.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  337M  100  337M    0     0  35.7M      0  0:00:09  0:00:09 --:--:-- 44.8M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz0b-5MpH_Hq"
      },
      "source": [
        "!unzip -q cell_images.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9yzJ10-IoDu"
      },
      "source": [
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkj9yCxXIq90",
        "outputId": "ae166c2f-77f4-461f-c208-d51264b9450a"
      },
      "source": [
        "num_skipped = 0\n",
        "for folder_name in (\"Parasitized\", \"Uninfected\"):\n",
        "    folder_path = os.path.join(\"cell_images\", folder_name)\n",
        "    for fname in os.listdir(folder_path):\n",
        "        fpath = os.path.join(folder_path, fname)\n",
        "        try:\n",
        "            fobj = open(fpath, \"rb\")\n",
        "            png_true = 'png' in fname\n",
        "        finally:\n",
        "            fobj.close()\n",
        "\n",
        "        if not png_true:\n",
        "            num_skipped += 1\n",
        "            # Delete corrupted image\n",
        "            os.remove(fpath)\n",
        "print(\"Deleted %d images\" % num_skipped)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deleted 2 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rRK0ooyMuMX"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AKlHdMSMu2H"
      },
      "source": [
        "image_size = (224, 224) #the images all have the same size \n",
        "batch_size = 32\n",
        "\n",
        "#seeding is fixed to get a 'fixed' random data set\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"cell_images\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"cell_images\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx546iUJM_I5"
      },
      "source": [
        "data_agumentation = keras.Sequential(\n",
        "    [\n",
        "     layers.experimental.preprocessing.RandomRotation((-0.3,0.3)),\n",
        "     layers.experimental.preprocessing.RandomZoom(0.5)\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcpOZiNjQbwd"
      },
      "source": [
        "train_ds = train_ds.prefetch(buffer_size=32)\n",
        "val_ds = val_ds.prefetch(buffer_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43m8MUj7QuGS"
      },
      "source": [
        "# Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Acn9MtkRQtpo"
      },
      "source": [
        "def VGG16_model(input_shape):\n",
        "  inputs = keras.Input(shape = input_shape)\n",
        "  #applying the agumentaions to my data\n",
        "  agumented_output = data_agumentation(inputs)\n",
        "\n",
        "  #rescaling as part of the model for GPU use\n",
        "  rescaled_output = layers.experimental.preprocessing.Rescaling(1/255)(agumented_output)\n",
        "  #convolutional blocks\n",
        "  for filter_num in [64,128]:\n",
        "    conv_output = layers.Conv2D(filter_num, 3, strides = 1, padding = 'same')(rescaled_output)\n",
        "    norm_output = layers.BatchNormalization()(conv_output)\n",
        "    actv_output = layers.Activation('relu')(norm_output)\n",
        "\n",
        "    conv_output = layers.Conv2D(filter_num, 3, strides = 1, padding = 'same')(actv_output)\n",
        "    norm_output = layers.BatchNormalization()(conv_output)\n",
        "    actv_output = layers.Activation('relu')(norm_output)\n",
        "\n",
        "    pool_output = layers.MaxPool2D(2,strides = 2)(actv_output)\n",
        "    rescaled_output = pool_output\n",
        "\n",
        "  rescaled_output = None #this variable served it purpose\n",
        "\n",
        "  for filter_num in [256,512,512]:\n",
        "\n",
        "    conv_output = layers.Conv2D(filter_num ,3, strides = 1, padding = 'same')(pool_output)\n",
        "    norm_output = layers.BatchNormalization()(conv_output)\n",
        "    actv_output = layers.Activation('relu')(norm_output)\n",
        "\n",
        "    conv_output = layers.Conv2D(filter_num ,3, strides = 1, padding = 'same')(actv_output)\n",
        "    norm_output = layers.BatchNormalization()(conv_output)\n",
        "    actv_output = layers.Activation('relu')(norm_output)\n",
        "\n",
        "\n",
        "    conv_output = layers.Conv2D(filter_num ,3, strides = 1, padding = 'same')(actv_output)\n",
        "    norm_output = layers.BatchNormalization()(conv_output)\n",
        "    actv_output = layers.Activation('relu')(norm_output)\n",
        "\n",
        "    pool_output = layers.MaxPool2D(2,strides = 2)(actv_output)\n",
        "\n",
        "  flatten_output = layers.Flatten()(pool_output)\n",
        "  \n",
        "  neuron_output = layers.Dense(256, activation = 'relu')(flatten_output)\n",
        "  neuron_output = layers.Dense(256, activation = 'relu')(neuron_output)\n",
        "  outputs = layers.Dense(1, activation = 'sigmoid')(neuron_output)\n",
        "\n",
        "  return keras.Model(inputs,outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PiyfivcZYd_",
        "collapsed": true
      },
      "source": [
        "model = VGG16_model(input_shape=image_size + (3,))\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtTV8aSNZWgz"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
        "]\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.fit(\n",
        "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCsKSREBgN3Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}